---
- name: Repmgr | Update configuration (repmgr.conf)
  template:
    src: "repmgr.conf-{{ repmgr_version }}.j2"
    dest: "{{postgresql_conf_directory}}/repmgr.conf"
    owner: "{{ postgresql_service_user }}"
    group: "{{ postgresql_service_group }}"
    mode: 0640

- name: Repmgr | Ensure systemd drop-in directory exists
  file:
    path: "/etc/systemd/system/repmgr{{postgresql_version}}.service.d/"
    state: directory
    mode: 0755

- name: Repmgr | Update drop-in
  template:
    src: "repmgr.custom.conf.j2"
    dest: "/etc/systemd/system/repmgr{{postgresql_version}}.service.d/custom.conf"

- name: Repmgr | Allow passwordless restarts with postgres user
  template:
    src: "sudoers.postgresql.j2"
    dest: "/etc/sudoers.d/postgresql"
    mode: 0640

- name: Repmgr | Update .pgpass for postgres user
  template:
    src: "pgpass.j2"
    dest: "{{repmgr_passfile}}"
    owner: "{{ postgresql_service_user }}"
    group: "{{ postgresql_service_group }}"
    mode: 0600
    trim_blocks: no

- name: Repmgr | Ensure ssh keys destination folder exists
  file: 
    path: "{{repmgr_base_key_path}}"
    state: directory
    owner: "{{ postgresql_service_user }}"
    group: "{{ postgresql_service_group }}"
    mode: 0700

- name: Rempgr | Generate local SSH keypair (Native module version)
  openssh_keypair:
    path: /tmp/id_rsa
    size: 2048
    owner: root
    mode: 0775
  delegate_to: localhost

- name: Repmgr | Fetch pubkey content
  set_fact:
    pubkey_content: "{{ lookup('file', '/tmp/id_rsa.pub') }}"
  become: yes

- debug: "var=pubkey_content"

- name: Repmgr | Update authorized_keys on all nodes
  authorized_key:
    user: "{{ postgresql_service_user }}"
    key: "{{pubkey_content}}"
    state: present

- name: Repmgr | Upload private key on all nodes
  copy:
    src: "/tmp/id_rsa"
    dest: "{{ repmgr_private_key_path }}"
    owner: "{{ postgresql_service_user }}"
    group: "{{ postgresql_service_group }}"
    mode: 0600

# TODO: refacto overall logic here : repmgr_cluster_show

- name: Repmgr | Check cluster status
  command: "{{postgresql_bin_directory}}/repmgr -f {{postgresql_conf_directory}}/repmgr.conf cluster show"
  become: yes
  become_user: "{{ postgresql_service_user }}"
  register: repmgr_cluster_show
  changed_when: repmgr_cluster_show.rc != 0
  ignore_errors: True

- name: Repmgr | Register as primary
  command: "{{postgresql_bin_directory}}/repmgr -f {{postgresql_conf_directory}}/repmgr.conf primary register"
  become: yes
  become_user: "{{ postgresql_service_user }}"
  when:
    - repmgr_primary and
      not ansible_hostname in repmgr_cluster_show.stdout and
      not "primary" in repmgr_cluster_show.stdout

- name: Repmgr | Ensure postgresql slave is stopped before clone
  service:
    name: "postgresql@{{postgresql_version}}-{{postgresql_cluster_name}}"
    state: stopped
  when: not repmgr_primary and not ansible_hostname in repmgr_cluster_show.stdout and not "standby" in repmgr_cluster_show.stdout

- name: Repmgr | Clone standby
  command: "{{postgresql_bin_directory}}/repmgr -F -h {% for host, vars in hostvars.items() if 'repmgr_primary' in vars and vars['repmgr_primary'] == True %}{{ host }}{% endfor %} -U repmgr -d repmgr -f {{postgresql_conf_directory}}/repmgr.conf standby clone"
  become: yes
  become_user: "{{ postgresql_service_user }}"
  when: not repmgr_primary and not ansible_hostname in  repmgr_cluster_show.stdout and not "standby" in repmgr_cluster_show.stdout

- name: Repmgr | Ensure postgresql slave is running after clone
  service:
    name: "postgresql-{{postgresql_version}}"
    state: started
  when: not repmgr_primary

- name: Repmgr | Wait for Postgres
  wait_for:
    timeout: 3
  delegate_to: localhost

- name: Repmgr | Register standby
  command: "{{postgresql_bin_directory}}/repmgr -F -h {% for host, vars in hostvars.items() if 'repmgr_primary' in vars and vars['repmgr_primary'] == True %}{{ host }}{% endfor %} -U repmgr -d repmgr -f {{postgresql_conf_directory}}/repmgr.conf standby register"
  become: yes
  become_user: "{{ postgresql_service_user }}"
  when: not repmgr_primary and not ansible_hostname in repmgr_cluster_show.stdout and not "standby" in repmgr_cluster_show.stdout

- name: Repmgr | Verify cluster functionality
  command: "{{postgresql_bin_directory}}/repmgr -F -h {% for host, vars in hostvars.items() if 'repmgr_primary' in vars and vars['repmgr_primary'] == True %}{{ host }}{% endfor %} -U repmgr -d repmgr -f {{postgresql_conf_directory}}/repmgr.conf cluster crosscheck"
  become: yes
  become_user: "{{ postgresql_service_user }}"

- name: Repmgr | Ensure repmgrd is running
  service:
    name: "repmgr{{postgresql_version}}"
    state: started
    enabled: yes
  when: repmgr_monitoring_history == "true" or repmgr_failover == "automatic"

- name: Repmgr | Ensure crontab is installed
  package:
    name: crontabs
  when: repmgr_monitoring_history == "true" or repmgr_failover == "automatic"

- name: Repmgr | Ensure crond is running
  service:
    name: "crond"
    state: started
    enabled: yes

- name: Repmgr | Setup cluster monitoring history cleanup
  copy:
    content: "{{postgresql_bin_directory}}/repmgr -f {{postgresql_conf_directory}}/repmgr.conf cluster cleanup --keep-history={{repmgr_keep_history_days}}"
    dest: "/etc/cron.daily/repmgr_cleanup"
    mode: 0755
  when: repmgr_monitoring_history == "true" or repmgr_failover == "automatic"
